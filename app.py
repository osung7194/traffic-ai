import streamlit as st
import cv2
import tempfile
import numpy as np
import datetime
import pandas as pd
from ultralytics import YOLO

# ÌéòÏù¥ÏßÄ ÏÑ§Ï†ï
st.set_page_config(page_title="OSUNG TRAFFIC AI", layout="wide")

st.title("üö¶ Ïò§ÏÑ±Í∞úÎ∞ú Ìä∏ÎûòÌîΩ ÎßàÏä§ÌÑ∞ (Web Î∞∞Ìè¨Ïö©)")

# Î™®Îç∏ Î°úÎìú (Ï∫êÏã±ÌïòÏó¨ ÏÜçÎèÑ ÏµúÏ†ÅÌôî)
@st.cache_resource
def load_model():
    return YOLO("yolov8n.pt")

model = load_model()

# ==========================================
# ‚öôÔ∏è Ìï≠ÏÉÅ ÌëúÏãúÎêòÎäî ÏÇ¨Ïù¥ÎìúÎ∞î ÏÑ§Ï†ï Î©îÎâ¥
# ==========================================
st.sidebar.header("‚öôÔ∏è 1. Î∂ÑÏÑù Í∏∞Î≥∏ ÏÑ§Ï†ï")

# 1. ÏÉÅÌñâ/ÌïòÌñâ ÏÑ†ÌÉùÎ≤ÑÌäº (Ìï≠ÏÉÅ Î≥¥ÏûÑ)
target_dir = st.sidebar.radio("Î∞©Ìñ• ÏÑ†ÌÉù (ÌÜµÍ≥º Í∏∞Ï§Ä)", ["‚ñº ÌïòÌñâ (ÏúÑÏóêÏÑú ÏïÑÎûòÎ°ú)", "‚ñ≤ ÏÉÅÌñâ (ÏïÑÎûòÏÑú ÏúÑÎ°ú)"])

# 2. Ïπ¥Ïö¥ÌåÖ ÎùºÏù∏ Ï°∞Ï†à (ÌôîÎ©¥ ÌîΩÏÖÄ 0~720 Í∏∞Ï§Ä)
line_y = st.sidebar.slider("üìè Ïπ¥Ïö¥ÌåÖ ÎùºÏù∏ ÏúÑÏπò (ÏúÑ/ÏïÑÎûò)", 0, 720, 400)

# 3. Ï∞®Îüâ ÌÅ¨Í∏∞ ÏÑ§Ï†ï (Ïà®ÍπÄ Î©îÎâ¥Î°ú ÍπîÎÅîÌïòÍ≤å)
with st.sidebar.expander("üõ†Ô∏è Ï∞®Îüâ ÌÅ¨Í∏∞ Î∞è ÌîΩÏÖÄ ÏÑ§Ï†ï (ÌÅ¥Î¶≠)"):
    pixels_per_meter = st.number_input("1mÎãπ ÌîΩÏÖÄ Ïàò (Í∏∞Î≥∏ 80)", value=80)
    th_car = st.slider("ÏäπÏö©/ÏÜåÌòïÌôîÎ¨º ÏµúÎåÄ(m)", 3.0, 15.0, 5.5)
    th_small_bus = st.slider("ÏÜåÌòïÎ≤ÑÏä§/Ï§ëÌòïÌôîÎ¨º ÏµúÎåÄ(m)", 3.0, 15.0, 8.5)
    th_large = st.slider("ÎåÄÌòï ÏµúÏÜå(m)", 5.0, 20.0, 9.5)

st.sidebar.markdown("---")

# ==========================================
# üìÅ ÎèôÏòÅÏÉÅ ÏóÖÎ°úÎìú Î∞è Ïã§Ìñâ ÏòÅÏó≠
# ==========================================
st.sidebar.header("üìÅ 2. ÎèôÏòÅÏÉÅ ÏóÖÎ°úÎìú")
uploaded_file = st.sidebar.file_uploader("ÏòÅÏÉÅÏùÑ Ïò¨Î†§Ï£ºÏÑ∏Ïöî (ÏµúÎåÄ 2GB)", type=["mp4", "avi", "mov"])

if uploaded_file is not None:
    # ÏòÅÏÉÅ ÏûÑÏãú Ï†ÄÏû•
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tfile.write(uploaded_file.read())
    temp_file_path = tfile.name

    # Ï≤´ ÌôîÎ©¥ ÎØ∏Î¶¨Î≥¥Í∏∞ Ï∂îÏ∂ú
    cap = cv2.VideoCapture(temp_file_path)
    ret, first_frame = cap.read()
    cap.release()

    if ret:
        first_frame = cv2.resize(first_frame, (1280, 720))
        preview_img = first_frame.copy()
        
        # ÎùºÏù∏ Í∑∏Î¶¨Í∏∞
        cv2.line(preview_img, (0, line_y), (1280, line_y), (0, 255, 255), 3)
        cv2.putText(preview_img, "COUNTING LINE", (10, line_y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        st.subheader("üì∫ Ï≤´ ÌôîÎ©¥ ÎØ∏Î¶¨Î≥¥Í∏∞ (ÏôºÏ™Ω ÏÑ§Ï†ïÎ∞îÏóêÏÑú ÎÖ∏ÎûÄ ÏÑ†ÏùÑ Ï°∞Ï†àÌïòÏÑ∏Ïöî)")
        st.image(preview_img, channels="BGR")

        st.markdown("---")
        
        # ÏãúÏûë Î≤ÑÌäº
        if st.button("‚ñ∂ Î≥∏Í≤©Ï†ÅÏù∏ Î∂ÑÏÑù ÏãúÏûë (ÌÅ¥Î¶≠)", use_container_width=True):
            cap = cv2.VideoCapture(temp_file_path)
            
            # Ïã§ÏãúÍ∞Ñ ÌôîÎ©¥Í≥º Îç∞Ïù¥ÌÑ∞ Ï∞Ω ÎÇòÎàÑÍ∏∞
            col_vid, col_data = st.columns([3, 1])
            frame_window = col_vid.empty()
            status_area = col_data.empty()
            
            counts = {"ÏäπÏö©Ï∞®": 0, "ÏÜåÌòïÎ≤ÑÏä§": 0, "ÎåÄÌòïÎ≤ÑÏä§": 0, "ÏÜåÌòïÌôîÎ¨º": 0, "Ï§ëÌòïÌôîÎ¨º": 0, "ÎåÄÌòïÌôîÎ¨º": 0}
            track_data = {}
            records = []

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break

                frame = cv2.resize(frame, (1280, 720))
                
                # YOLO AI Ï∂îÏ†Å
                results = model.track(frame, persist=True, verbose=False, classes=[2, 5, 7], conf=0.25)
                
                if results[0].boxes.id is not None:
                    boxes = results[0].boxes.xywh.cpu()
                    ids = results[0].boxes.id.int().cpu().tolist()
                    clss = results[0].boxes.cls.int().cpu().tolist()
                    
                    for box, tid, cls in zip(boxes, ids, clss):
                        # [Ïò§Î•ò Ìï¥Í≤∞] TensorÎ•º float Ïà´ÏûêÎ°ú ÏôÑÏ†Ñ Î≥ÄÌôò
                        bx, by, bw, bh = float(box[0]), float(box[1]), float(box[2]), float(box[3])
                        cx, cy = bx, by
                        
                        if tid not in track_data:
                            track_data[tid] = {'path': [], 'done': False}
                        
                        path = track_data[tid]['path']
                        path.append((cx, cy))
                        
                        if not track_data[tid]['done'] and len(path) >= 2:
                            prev_y, curr_y = path[-2][1], path[-1][1]
                            
                            # ÏÑ† ÌÜµÍ≥º ÌôïÏù∏
                            if (prev_y <= line_y <= curr_y) or (curr_y <= line_y <= prev_y):
                                moving_down = (curr_y - path[0][1]) > 0
                                
                                # Î∞©Ìñ• ÏùºÏπò ÌôïÏù∏
                                if ("ÌïòÌñâ" in target_dir and moving_down) or ("ÏÉÅÌñâ" in target_dir and not moving_down):
                                    
                                    pixel_len = max(bw, bh)
                                    real_len = float(pixel_len / pixels_per_meter)
                                    
                                    # 6Ï¢Ö Î∂ÑÎ•ò
                                    v_type = "ÏäπÏö©Ï∞®"
                                    if cls == 2:
                                        v_type = "ÏäπÏö©Ï∞®" if real_len < th_car else "Ï§ëÌòïÌôîÎ¨º"
                                    elif cls == 5:
                                        v_type = "ÏÜåÌòïÎ≤ÑÏä§" if real_len < th_small_bus else "ÎåÄÌòïÎ≤ÑÏä§"
                                    elif cls == 7:
                                        if real_len < th_car: v_type = "ÏÜåÌòïÌôîÎ¨º"
                                        elif real_len < th_small_bus: v_type = "Ï§ëÌòïÌôîÎ¨º"
                                        else: v_type = "ÎåÄÌòïÌôîÎ¨º"
                                    
                                    counts[v_type] += 1
                                    track_data[tid]['done'] = True
                                    records.append([datetime.datetime.now().strftime("%H:%M:%S"), v_type, round(real_len, 1)])

                # ÌôîÎ©¥Ïóê ÏÑ† Í∑∏Î¶¨Í∏∞
                cv2.line(frame, (0, line_y), (1280, line_y), (0, 255, 255), 3)
                frame_window.image(frame, channels="BGR")
                
                # Ïã§ÏãúÍ∞Ñ ÌòÑÌô©Ìåê
                res_txt = "### üìä Ïπ¥Ïö¥ÌåÖ ÌòÑÌô©\n"
                for k, v in counts.items():
                    res_txt += f"- **{k}**: {v}ÎåÄ\n"
                status_area.markdown(res_txt)

            cap.release()
            
            # --- Î∂ÑÏÑù Ï¢ÖÎ£å ÌõÑ Îã§Ïö¥Î°úÎìú ---
            st.success("‚úÖ Î∂ÑÏÑù ÏôÑÎ£å! ÏïÑÎûò Î≤ÑÌäºÏùÑ ÎàåÎü¨ Í≤∞Í≥º ÏóëÏÖÄ(CSV)ÏùÑ Ï†ÄÏû•ÌïòÏÑ∏Ïöî.")
            if records:
                df = pd.DataFrame(records, columns=["ÌÜµÍ≥ºÏãúÍ∞Ñ", "Ï∞®Ï¢ÖÎ∂ÑÎ•ò", "Ï∂îÏ†ïÍ∏∏Ïù¥(m)"])
                csv = df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("üì• Î∂ÑÏÑù Í≤∞Í≥º (ÏóëÏÖÄ CSV) Îã§Ïö¥Î°úÎìú", data=csv, file_name="ÍµêÌÜµÎüâÍ≤∞Í≥º.csv", mime="text/csv", use_container_width=True)
else:
    st.info("üëà ÏôºÏ™ΩÏóêÏÑú Î∂ÑÏÑùÌï† Î∞©Ìñ•, ÎùºÏù∏ ÏúÑÏπòÎ•º Î®ºÏ†Ä ÏÑ§Ï†ïÌïòÍ≥† ÎèôÏòÅÏÉÅÏùÑ Ïò¨Î†§Ï£ºÏÑ∏Ïöî.")