import streamlit as st
import cv2
import tempfile
import numpy as np
import datetime
import pandas as pd
from ultralytics import YOLO

# ÌéòÏù¥ÏßÄ ÏÑ§Ï†ï
st.set_page_config(page_title="OSUNG TRAFFIC AI", layout="wide")
st.title("üö¶ Ïò§ÏÑ±Í∞úÎ∞ú Ìä∏ÎûòÌîΩ ÎßàÏä§ÌÑ∞ (Web Î∞∞Ìè¨Ïö©)")

@st.cache_resource
def load_model():
    return YOLO("yolov8n.pt")

model = load_model()

# --- ÏÇ¨Ïù¥ÎìúÎ∞î ÏÑ§Ï†ï ---
st.sidebar.header("‚öôÔ∏è 1. Î∂ÑÏÑù Í∏∞Î≥∏ ÏÑ§Ï†ï")
target_dir = st.sidebar.radio("Î∞©Ìñ• ÏÑ†ÌÉù", ["‚ñº ÌïòÌñâ (ÏúÑÏóêÏÑú ÏïÑÎûòÎ°ú)", "‚ñ≤ ÏÉÅÌñâ (ÏïÑÎûòÏÑú ÏúÑÎ°ú)"])
line_y = st.sidebar.slider("üìè Ïπ¥Ïö¥ÌåÖ ÎùºÏù∏ ÏúÑÏπò", 0, 720, 400)

with st.sidebar.expander("üõ†Ô∏è Ï∞®Îüâ ÌÅ¨Í∏∞ Î∞è ÌîΩÏÖÄ ÏÑ§Ï†ï"):
    pixels_per_meter = st.number_input("1mÎãπ ÌîΩÏÖÄ Ïàò", value=80)
    th_car = st.slider("ÏäπÏö©/ÏÜåÌòïÌôîÎ¨º ÏµúÎåÄ(m)", 3.0, 15.0, 5.5)
    th_small_bus = st.slider("ÏÜåÌòïÎ≤ÑÏä§/Ï§ëÌòïÌôîÎ¨º ÏµúÎåÄ(m)", 3.0, 15.0, 8.5)
    th_large = st.slider("ÎåÄÌòï ÏµúÏÜå(m)", 5.0, 20.0, 9.5)

st.sidebar.header("üìÅ 2. ÎèôÏòÅÏÉÅ ÏóÖÎ°úÎìú")
uploaded_file = st.sidebar.file_uploader("ÏòÅÏÉÅÏùÑ Ïò¨Î†§Ï£ºÏÑ∏Ïöî (200MB Ï†úÌïú)", type=["mp4", "avi", "mov"])

if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tfile.write(uploaded_file.read())
    temp_file_path = tfile.name

    cap = cv2.VideoCapture(temp_file_path)
    ret, first_frame = cap.read()
    cap.release()

    if ret:
        first_frame = cv2.resize(first_frame, (1280, 720))
        preview_img = first_frame.copy()
        cv2.line(preview_img, (0, line_y), (1280, line_y), (0, 255, 255), 3)
        st.subheader("üì∫ Ï≤´ ÌôîÎ©¥ ÎØ∏Î¶¨Î≥¥Í∏∞ (ÎÖ∏ÎûÄ ÏÑ†ÏùÑ Ï°∞Ï†àÌïòÏÑ∏Ïöî)")
        st.image(preview_img, channels="BGR")

        if st.button("‚ñ∂ Î≥∏Í≤©Ï†ÅÏù∏ Î∂ÑÏÑù ÏãúÏûë", use_container_width=True):
            cap = cv2.VideoCapture(temp_file_path)
            col_vid, col_data = st.columns([3, 1])
            frame_window = col_vid.empty()
            status_area = col_data.empty()
            
            counts = {"ÏäπÏö©Ï∞®": 0, "ÏÜåÌòïÎ≤ÑÏä§": 0, "ÎåÄÌòïÎ≤ÑÏä§": 0, "ÏÜåÌòïÌôîÎ¨º": 0, "Ï§ëÌòïÌôîÎ¨º": 0, "ÎåÄÌòïÌôîÎ¨º": 0}
            track_data = {}
            records = []

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break
                frame = cv2.resize(frame, (1280, 720))
                
                results = model.track(frame, persist=True, verbose=False, classes=[2, 5, 7], conf=0.25)
                
                if results[0].boxes.id is not None:
                    boxes = results[0].boxes.xywh.cpu()
                    ids = results[0].boxes.id.int().cpu().tolist()
                    clss = results[0].boxes.cls.int().cpu().tolist()
                    
                    for box, tid, cls in zip(boxes, ids, clss):
                        bx, by, bw, bh = float(box[0]), float(box[1]), float(box[2]), float(box[3])
                        cx, cy = bx, by
                        
                        if tid not in track_data:
                            track_data[tid] = {'path': [], 'done': False}
                        path = track_data[tid]['path']
                        path.append((cx, cy))
                        
                        if not track_data[tid]['done'] and len(path) >= 2:
                            prev_y, curr_y = path[-2][1], path[-1][1]
                            if (prev_y <= line_y <= curr_y) or (curr_y <= line_y <= prev_y):
                                moving_down = (curr_y - path[0][1]) > 0
                                if ("ÌïòÌñâ" in target_dir and moving_down) or ("ÏÉÅÌñâ" in target_dir and not moving_down):
                                    pixel_len = max(bw, bh)
                                    real_len = float(pixel_len / pixels_per_meter)
                                    
                                    v_type = "ÏäπÏö©Ï∞®"
                                    if cls == 2: v_type = "ÏäπÏö©Ï∞®" if real_len < th_car else "Ï§ëÌòïÌôîÎ¨º"
                                    elif cls == 5: v_type = "ÏÜåÌòïÎ≤ÑÏä§" if real_len < th_small_bus else "ÎåÄÌòïÎ≤ÑÏä§"
                                    elif cls == 7:
                                        if real_len < th_car: v_type = "ÏÜåÌòïÌôîÎ¨º"
                                        elif real_len < th_small_bus: v_type = "Ï§ëÌòïÌôîÎ¨º"
                                        else: v_type = "ÎåÄÌòïÌôîÎ¨º"
                                    
                                    counts[v_type] += 1
                                    track_data[tid]['done'] = True
                                    records.append([datetime.datetime.now().strftime("%H:%M:%S"), v_type, round(real_len, 1)])

                # --- ÏóêÎü¨ Î∞©ÏßÄÎ•º ÏúÑÌï¥ Í∏ÄÏûê Ïì∞Í∏∞ Í∏∞Îä•ÏùÑ ÏµúÏÜåÌôîÌïòÍ≥† ÏÑ†Îßå Í∑∏Î¶ΩÎãàÎã§ ---
                cv2.line(frame, (0, line_y), (1280, line_y), (0, 255, 255), 2)
                frame_window.image(frame, channels="BGR")
                
                res_txt = "### üìä Ïπ¥Ïö¥ÌåÖ ÌòÑÌô©\n"
                for k, v in counts.items():
                    res_txt += f"- **{k}**: {v}ÎåÄ\n"
                status_area.markdown(res_txt)

            cap.release()
            st.success("‚úÖ Î∂ÑÏÑù ÏôÑÎ£å!")
            if records:
                df = pd.DataFrame(records, columns=["ÌÜµÍ≥ºÏãúÍ∞Ñ", "Ï∞®Ï¢ÖÎ∂ÑÎ•ò", "Ï∂îÏ†ïÍ∏∏Ïù¥(m)"])
                csv = df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("üì• Í≤∞Í≥º Îã§Ïö¥Î°úÎìú", data=csv, file_name="result.csv")
else:
    st.info("üëà ÏòÅÏÉÅÏùÑ Ïò¨Î†§Ï£ºÏÑ∏Ïöî.")
